#utils.py
#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
-------------------------------------------------
   @File Name:     utils.py
   @Author:        Luyao.zhang
   @Date:          2023/5/16
   @Description:
-------------------------------------------------
"""
from ultralytics import YOLO
import streamlit as st
import cv2
from PIL import Image
import tempfile

def _display_detected_frames(conf, model, st_frame, image):
    """
    ä½¿ç”¨YOLOv8æ¨¡å‹åœ¨è§†é¢‘å¸§ä¸Šæ˜¾ç¤ºæ£€æµ‹åˆ°çš„å¯¹è±¡ã€‚
    :param conf (float): å¯¹è±¡æ£€æµ‹çš„ç½®ä¿¡åº¦é˜ˆå€¼ã€‚
    :param model (YOLOv8): åŒ…å«YOLOv8æ¨¡å‹çš„`YOLOv8`ç±»çš„å®ä¾‹ã€‚
    :param st_frame (Streamlitå¯¹è±¡): ç”¨äºæ˜¾ç¤ºæ£€æµ‹è§†é¢‘çš„Streamlitå¯¹è±¡ã€‚
    :param image (numpyæ•°ç»„): è¡¨ç¤ºè§†é¢‘å¸§çš„numpyæ•°ç»„ã€‚
    :return: None
    """
    # å°†å›¾åƒè°ƒæ•´ä¸ºæ ‡å‡†å¤§å°
    image = cv2.resize(image, (720, int(720 * (9 / 16))))

    # ä½¿ç”¨YOLOv8æ¨¡å‹é¢„æµ‹å›¾åƒä¸­çš„å¯¹è±¡
    res = model.predict(image, conf=conf)

    # åœ¨è§†é¢‘å¸§ä¸Šç»˜åˆ¶æ£€æµ‹åˆ°çš„å¯¹è±¡
    res_plotted = res[0].plot()
    st_frame.image(res_plotted,
                   caption='æ£€æµ‹è§†é¢‘',
                   channels="BGR",
                   use_column_width=True
                   )

@st.cache_resource
def load_model(model_path):
    """
    ä»æŒ‡å®šçš„model_pathåŠ è½½YOLOå¯¹è±¡æ£€æµ‹æ¨¡å‹ã€‚

    å‚æ•°:
        model_path (str): YOLOæ¨¡å‹æ–‡ä»¶çš„è·¯å¾„ã€‚

    è¿”å›:
        ä¸€ä¸ªYOLOå¯¹è±¡æ£€æµ‹æ¨¡å‹ã€‚
    """
    model = YOLO(model_path)
    return model

def infer_uploaded_image(conf, model):
    """
    å¯¹ä¸Šä¼ çš„å›¾ç‰‡æ‰§è¡Œæ¨ç†
    :param conf: YOLOv8æ¨¡å‹çš„ç½®ä¿¡åº¦
    :param model: åŒ…å«YOLOv8æ¨¡å‹çš„`YOLOv8`ç±»çš„å®ä¾‹ã€‚
    :return: None
    """
    source_img = st.sidebar.file_uploader(
        label="é€‰æ‹©ä¸€å¼ å›¾ç‰‡...",
        type=("jpg", "jpeg", "png", 'bmp', 'webp')
    )

    col1, col2 = st.columns(2)

    with col1:
        if source_img:
            uploaded_image = Image.open(source_img)
            st.image(
                image=source_img,
                caption="ä¸Šä¼ çš„å›¾ç‰‡",
                use_column_width=True
            )

    if source_img:
        if st.button("å¼€å§‹æ‰§è¡Œ"):
            with st.spinner("æ‰§è¡Œä¸­..."):
                res = model.predict(uploaded_image,
                                    conf=conf)
                boxes = res[0].boxes
                res_plotted = res[0].plot()[:, :, ::-1]

                with col2:
                    st.image(res_plotted,
                             caption="æ£€æµ‹ç»“æœ",
                             use_column_width=True)
                    try:
                        with st.expander("æ£€æµ‹ç»“æœè¯¦æƒ…"):
                            for box in boxes:
                                st.write(f"ä½ç½®åŠå¤§å°: {box.xywh}")
                    except Exception as ex:
                        st.write("å°šæœªä¸Šä¼ å›¾ç‰‡ï¼")
                        st.write(ex)

def infer_uploaded_video(conf, model):
    """
    å¯¹ä¸Šä¼ çš„è§†é¢‘æ‰§è¡Œæ¨ç†
    :param conf: YOLOv8æ¨¡å‹çš„ç½®ä¿¡åº¦
    :param model: åŒ…å«YOLOv8æ¨¡å‹çš„`YOLOv8`ç±»çš„å®ä¾‹ã€‚
    :return: None
    """
    source_video = st.sidebar.file_uploader(
        label="é€‰æ‹©ä¸€ä¸ªè§†é¢‘..."
    )

    if source_video:
        st.video(source_video)

    if source_video:
        if st.button("å¼€å§‹æ‰§è¡Œ"):
            with st.spinner("æ‰§è¡Œä¸­..."):
                try:
                    tfile = tempfile.NamedTemporaryFile()
                    tfile.write(source_video.read())
                    vid_cap = cv2.VideoCapture(tfile.name)
                    st_frame = st.empty()
                    while vid_cap.isOpened():
                        success, image = vid_cap.read()
                        if success:
                            _display_detected_frames(conf, model, st_frame, image)
                        else:
                            vid_cap.release()
                            break
                except Exception as e:
                    st.error(f"åŠ è½½è§†é¢‘å‡ºé”™: {e}")

def infer_uploaded_webcam(conf, model):
    """
    æ‰§è¡Œç½‘ç»œæ‘„åƒå¤´çš„æ¨ç†ã€‚
    :param conf: YOLOv8æ¨¡å‹çš„ç½®ä¿¡åº¦
    :param model: åŒ…å«YOLOv8æ¨¡å‹çš„`YOLOv8`ç±»çš„å®ä¾‹ã€‚
    :return: None
    """
    try:
        flag = st.button("åœæ­¢è¿è¡Œ")
        vid_cap = cv2.VideoCapture(0)  # æœ¬åœ°æ‘„åƒå¤´
        st_frame = st.empty()
        while not flag:
            success, image = vid_cap.read()
            if success:
                _display_detected_frames(conf, model, st_frame, image)
            else:
                vid_cap.release()
                break
    except Exception as e:
        st.error(f"åŠ è½½è§†é¢‘å‡ºé”™: {str(e)}")


#qpp.py
#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
-------------------------------------------------
   @File Name:     app.py
   @Author:        Luyao.zhang
   @Date:          2023/5/15
   @Description: ä¸€ä¸ªäº¤äº’å¼ç•Œé¢ï¼Œç”¨äºYOLOv8å¯¹è±¡æ£€æµ‹
-------------------------------------------------
"""
from pathlib import Path
from PIL import Image
import streamlit as st

import config
from utils import load_model, infer_uploaded_image, infer_uploaded_video, infer_uploaded_webcam

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="YOLOv8äº¤äº’ç•Œé¢",
    page_icon="ğŸ¤–",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ä¸»é¡µé¢æ ‡é¢˜
st.title("YOLOv8äº¤äº’ç•Œé¢")

# ä¾§è¾¹æ 
st.sidebar.header("æ·±åº¦å­¦ä¹ æ¨¡å‹é…ç½®")

# é€‰æ‹©ä»»åŠ¡ç±»å‹
task_type = st.sidebar.selectbox(
    "é€‰æ‹©ä»»åŠ¡ç±»å‹",
    ["æ£€æµ‹"]
)

model_type = None
if task_type == "æ£€æµ‹":
    model_type = st.sidebar.selectbox(
        "é€‰æ‹©æ¨¡å‹",
        config.DETECTION_MODEL_LIST
    )
else:
    st.error("å½“å‰ä»…å®ç°äº†'æ£€æµ‹'åŠŸèƒ½")

confidence = float(st.sidebar.slider(
    "é€‰æ‹©æ¨¡å‹ç½®ä¿¡åº¦", 30, 100, 50)) / 100

model_path = ""
if model_type:
    model_path = Path(config.DETECTION_MODEL_DIR, str(model_type))
else:
    st.error("è¯·åœ¨ä¾§è¾¹æ ä¸­é€‰æ‹©æ¨¡å‹")

# åŠ è½½é¢„è®­ç»ƒçš„æ·±åº¦å­¦ä¹ æ¨¡å‹
try:
    model = load_model(model_path)
except Exception as e:
    st.error(f"æ— æ³•åŠ è½½æ¨¡å‹ï¼Œè¯·æ£€æŸ¥æŒ‡å®šçš„è·¯å¾„ï¼š{model_path}")

# å›¾åƒ/è§†é¢‘é€‰é¡¹
st.sidebar.header("å›¾åƒ/è§†é¢‘é…ç½®")
source_selectbox = st.sidebar.selectbox(
    "é€‰æ‹©æ•°æ®æº",
    config.SOURCES_LIST
)

if source_selectbox == config.SOURCES_LIST[0]:  # å›¾åƒ
    infer_uploaded_image(confidence, model)
elif source_selectbox == config.SOURCES_LIST[1]:  # è§†é¢‘
    infer_uploaded_video(confidence, model)
elif source_selectbox == config.SOURCES_LIST[2]:  # æ‘„åƒå¤´
    infer_uploaded_webcam(confidence, model)
else:
    st.error("å½“å‰ä»…å®ç°äº†'å›¾åƒ'å’Œ'è§†é¢‘'æ•°æ®æº")


#config.py
#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
-------------------------------------------------
   @File Name:     config.py
   @Author:        Luyao.zhang
   @Date:          2023/5/16
   @Description: configuration file
-------------------------------------------------
"""
from pathlib import Path
import sys

# Get the absolute path of the current file
file_path = Path(__file__).resolve()

# Get the parent directory of the current file
root_path = file_path.parent

# Add the root path to the sys.path list if it is not already there
if root_path not in sys.path:
    sys.path.append(str(root_path))

# Get the relative path of the root directory with respect to the current working directory
ROOT = root_path.relative_to(Path.cwd())


# Source
SOURCES_LIST = ["Image", "Video", "Webcam"]


# DL model config
DETECTION_MODEL_DIR = ROOT / 'weights' / 'detection'
YOLOv8n = DETECTION_MODEL_DIR / "yolov8n.pt"
YOLOv8s = DETECTION_MODEL_DIR / "yolov8s.pt"
YOLOv8m = DETECTION_MODEL_DIR / "yolov8m.pt"
YOLOv8l = DETECTION_MODEL_DIR / "yolov8l.pt"
YOLOv8x = DETECTION_MODEL_DIR / "yolov8x.pt"

DETECTION_MODEL_LIST = [
    "yolov8n.pt",
    "yolov8s.pt",
    "yolov8m.pt",
    "yolov8l.pt",
    "yolov8x.pt"]
